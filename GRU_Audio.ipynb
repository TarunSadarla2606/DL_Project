{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1978289,"sourceType":"datasetVersion","datasetId":1182338}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"zaber666/meld-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:30.317361Z","iopub.execute_input":"2025-04-21T15:46:30.317765Z","iopub.status.idle":"2025-04-21T15:46:30.791454Z","shell.execute_reply.started":"2025-04-21T15:46:30.317724Z","shell.execute_reply":"2025-04-21T15:46:30.790295Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/meld-dataset\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load datasets\ntrain_path = \"/kaggle/input/meld-dataset/MELD-RAW/MELD.Raw/train/train_sent_emo.csv\"\ntest_path = \"/kaggle/input/meld-dataset/MELD-RAW/MELD.Raw/test_sent_emo.csv\"\nval_path = \"/kaggle/input/meld-dataset/MELD-RAW/MELD.Raw/dev_sent_emo.csv\"\n\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\nval_df = pd.read_csv(val_path)\n\n# Extract labels\ntrain_sentiment = train_df[\"Sentiment\"]\nval_sentiment = val_df[\"Sentiment\"]\ntest_sentiment = test_df[\"Sentiment\"]\n\ntrain_emotion = train_df[\"Emotion\"]\nval_emotion = val_df[\"Emotion\"]\ntest_emotion = test_df[\"Emotion\"]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\nfrom tensorflow.keras.models import load_model\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Load Feature Data\nwith open('/kaggle/input/meld-dataset/MELD-Features-Models/MELD.Features.Models/features/audio_embeddings_feature_selection_emotion.pkl', 'rb') as a:\n    pre_audio_features_emotion = pickle.load(a)\nprint(type(pre_audio_features_emotion))\nprint(len(pre_audio_features_emotion))\n\nwith open('/kaggle/input/meld-dataset/MELD-Features-Models/MELD.Features.Models/features/audio_emotion.pkl', 'rb') as b:\n    audio_features_emotion = pickle.load(b)\nprint(type(audio_features_emotion))\nprint(len(audio_features_emotion))\n\nwith open('/kaggle/input/meld-dataset/MELD-Features-Models/MELD.Features.Models/features/audio_embeddings_feature_selection_sentiment.pkl', 'rb') as c:\n    pre_audio_features_sentiment = pickle.load(c)\nprint(type(pre_audio_features_sentiment))\nprint(len(pre_audio_features_sentiment))\n\nwith open('/kaggle/input/meld-dataset/MELD-Features-Models/MELD.Features.Models/features/audio_sentiment.pkl', 'rb') as d:\n    audio_features_sentiment = pickle.load(d)\nprint(type(audio_features_sentiment))\nprint(len(audio_features_sentiment))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:31.980300Z","iopub.execute_input":"2025-04-21T15:46:31.980665Z","iopub.status.idle":"2025-04-21T15:46:35.782564Z","shell.execute_reply.started":"2025-04-21T15:46:31.980627Z","shell.execute_reply":"2025-04-21T15:46:35.781542Z"}},"outputs":[{"name":"stdout","text":"<class 'list'>\n3\n<class 'list'>\n3\n<class 'list'>\n3\n<class 'list'>\n3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Unpack the list\nX1_train, X1_val, X1_test = pre_audio_features_emotion\n\n# Check the keys in each set\n#print(\"Train keys:\", X1_train.keys())\n#print(\"Validation keys:\", X1_val.keys())\n#print(\"Test keys:\", X1_test.keys())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:35.784453Z","iopub.execute_input":"2025-04-21T15:46:35.785107Z","iopub.status.idle":"2025-04-21T15:46:35.789702Z","shell.execute_reply.started":"2025-04-21T15:46:35.785070Z","shell.execute_reply":"2025-04-21T15:46:35.788425Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def get_audio_features(df, feature_dict):\n    utt_ids = df['Dialogue_ID'].astype(str) + \"_\" + df['Utterance_ID'].astype(str)\n    features = np.array([feature_dict[utt_id] for utt_id in utt_ids if utt_id in feature_dict])\n    return features\n\n# Extract aligned features\nX1_train_aligned = get_audio_features(train_df, X1_train)\nX1_val_aligned = get_audio_features(val_df, X1_val)\nX1_test_aligned = get_audio_features(test_df, X1_test)\n\n# Check shapes\nprint(\"Train features shape:\", X1_train_aligned.shape)\nprint(\"Validation features shape:\", X1_val_aligned.shape)\nprint(\"Test features shape:\", X1_test_aligned.shape)\n\n# Optional: sanity check against label dataframes\nprint(\"\\nTrain labels count:\", len(train_df))\nprint(\"Validation labels count:\", len(val_df))\nprint(\"Test labels count:\", len(test_df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:35.790813Z","iopub.execute_input":"2025-04-21T15:46:35.791155Z","iopub.status.idle":"2025-04-21T15:46:35.889440Z","shell.execute_reply.started":"2025-04-21T15:46:35.791126Z","shell.execute_reply":"2025-04-21T15:46:35.888405Z"}},"outputs":[{"name":"stdout","text":"Train features shape: (9989, 1611)\nValidation features shape: (1109, 1611)\nTest features shape: (2610, 1611)\n\nTrain labels count: 9989\nValidation labels count: 1109\nTest labels count: 2610\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Load Labels\ny_train = train_df[\"Emotion\"].values\ny_val = val_df[\"Emotion\"].values\ny_test = test_df[\"Emotion\"].values\n\n# Encode labels\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_val_encoded = label_encoder.transform(y_val)\ny_test_encoded = label_encoder.transform(y_test)\n\n# One-hot encode for model compatibility (if needed)\n#from tensorflow.keras.utils import to_categorical\n#y_train_cat = to_categorical(y_train_encoded)\n#y_val_cat = to_categorical(y_val_encoded)\n#y_test_cat = to_categorical(y_test_encoded)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:35.890468Z","iopub.execute_input":"2025-04-21T15:46:35.890821Z","iopub.status.idle":"2025-04-21T15:46:35.900620Z","shell.execute_reply.started":"2025-04-21T15:46:35.890793Z","shell.execute_reply":"2025-04-21T15:46:35.899342Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from keras.models import load_model\nfrom keras.layers import GRU, Dense, Dropout, Bidirectional, Input\nfrom keras import Sequential\nimport tensorflow as tf\n\ntf.config.run_functions_eagerly(True)\n\n# Include all possible layer types used in the model\ncustom_objects = {\n    'GRU': GRU,\n    'Dense': Dense,\n    'Dropout': Dropout,\n    'Bidirectional': Bidirectional,\n    'Sequential': Sequential,\n    'Input': Input\n}\n\n# Load the model\nemotion_model = load_model(\n    '/kaggle/input/meld-dataset/MELD-Features-Models/MELD.Features.Models/models/audio_weights_emotion.hdf5',\n    custom_objects=custom_objects, compile=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:35.901959Z","iopub.execute_input":"2025-04-21T15:46:35.902280Z","iopub.status.idle":"2025-04-21T15:46:36.165966Z","shell.execute_reply.started":"2025-04-21T15:46:35.902230Z","shell.execute_reply":"2025-04-21T15:46:36.164864Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Trim to make it divisible by 33\ntrim_size = X1_val_aligned.shape[0] - (X1_val_aligned.shape[0] % 33)\nX1_val_trimmed = X1_val_aligned[:trim_size]\n\n# Reshape to (num_sequences, 33, 1611)\nX1_val_reshaped = X1_val_trimmed.reshape(-1, 33, 1611)\n\n# Test set\ntrim_size_test = X1_test_aligned.shape[0] - (X1_test_aligned.shape[0] % 33)\nX1_test_trimmed = X1_test_aligned[:trim_size_test]\nX1_test_reshaped = X1_test_trimmed.reshape(-1, 33, 1611)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:36.166977Z","iopub.execute_input":"2025-04-21T15:46:36.167294Z","iopub.status.idle":"2025-04-21T15:46:36.173376Z","shell.execute_reply.started":"2025-04-21T15:46:36.167267Z","shell.execute_reply":"2025-04-21T15:46:36.172043Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Validation\n# Trim features\ntrim_size_val = X1_val_aligned.shape[0] - (X1_val_aligned.shape[0] % 33)\nX1_val_trimmed = X1_val_aligned[:trim_size_val]\nX1_val_reshaped = X1_val_trimmed.reshape(-1, 33, 1611)\n\n# Trim labels accordingly\ny_val_trimmed = y_val_encoded[:trim_size_val]\n\n# Predict\nval_preds = emotion_model.predict(X1_val_reshaped)\nprint(\"val_preds.shape:\", val_preds.shape)\n\n# Reshape model predictions to (1089, 7)\nval_preds_flat = val_preds.reshape(-1, val_preds.shape[-1])  # (1089, 7)\nval_preds_labels = np.argmax(val_preds_flat, axis=1)\n\ny_val_trimmed = y_val_encoded[:len(val_preds_labels)]\n\nprint(\"Validation Accuracy:\", accuracy_score(y_val_trimmed, val_preds_labels))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:36.174470Z","iopub.execute_input":"2025-04-21T15:46:36.174859Z","iopub.status.idle":"2025-04-21T15:46:37.779583Z","shell.execute_reply.started":"2025-04-21T15:46:36.174828Z","shell.execute_reply":"2025-04-21T15:46:37.778458Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step\nval_preds.shape: (33, 33, 7)\nValidation Accuracy: 0.09733700642791551\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Testing\n# Trim features\ntrim_size_test = X1_test_aligned.shape[0] - (X1_test_aligned.shape[0] % 33)\nX1_test_trimmed = X1_test_aligned[:trim_size_test]\nX1_test_reshaped = X1_test_trimmed.reshape(-1, 33, 1611)\n\n# Trim labels accordingly\ny_test_trimmed = y_test_encoded[:trim_size_test]\n\n# Predict\ntest_preds = emotion_model.predict(X1_test_reshaped)\nprint(\"test_preds.shape:\", test_preds.shape)\n\n# Reshape model predictions to (1089, 7)\ntest_preds_flat = test_preds.reshape(-1, test_preds.shape[-1])  # (1089, 7)\ntest_preds_labels = np.argmax(test_preds_flat, axis=1)\n\ny_test_trimmed = y_test_encoded[:len(test_preds_labels)]\n\n# Now it's safe\nprint(\"Test Accuracy:\", accuracy_score(y_test_trimmed, test_preds_labels))\nprint(\"\\nTest Classification Report:\")\nprint(classification_report(y_test_trimmed, test_preds_labels, target_names=label_encoder.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:37.780741Z","iopub.execute_input":"2025-04-21T15:46:37.781084Z","iopub.status.idle":"2025-04-21T15:46:39.818760Z","shell.execute_reply.started":"2025-04-21T15:46:37.781056Z","shell.execute_reply":"2025-04-21T15:46:39.817549Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 624ms/step\ntest_preds.shape: (79, 33, 7)\nTest Accuracy: 0.09167625623321826\n\nTest Classification Report:\n              precision    recall  f1-score   support\n\n       anger       0.09      0.54      0.16       345\n     disgust       0.00      0.00      0.00        68\n        fear       0.00      0.00      0.00        50\n         joy       0.00      0.00      0.00       402\n     neutral       0.19      0.00      0.01      1253\n     sadness       0.00      0.00      0.00       208\n    surprise       0.10      0.17      0.13       281\n\n    accuracy                           0.09      2607\n   macro avg       0.06      0.10      0.04      2607\nweighted avg       0.12      0.09      0.04      2607\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Unpack the list\nX2_train, X2_val, X2_test = pre_audio_features_sentiment\n\n# Check the keys in each set\n#print(\"Train keys:\", X2_train.keys())\n#print(\"Validation keys:\", X1_val.keys())\n#print(\"Test keys:\", X2_test.keys())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:39.820070Z","iopub.execute_input":"2025-04-21T15:46:39.820511Z","iopub.status.idle":"2025-04-21T15:46:39.825117Z","shell.execute_reply.started":"2025-04-21T15:46:39.820468Z","shell.execute_reply":"2025-04-21T15:46:39.823788Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Extract aligned features\nX2_train_aligned = get_audio_features(train_df, X2_train)\nX2_val_aligned = get_audio_features(val_df, X2_val)\nX2_test_aligned = get_audio_features(test_df, X2_test)\n\n# Check shapes\nprint(\"Train features shape:\", X2_train_aligned.shape)\nprint(\"Validation features shape:\", X2_val_aligned.shape)\nprint(\"Test features shape:\", X2_test_aligned.shape)\n\n# Optional: sanity check against label dataframes\nprint(\"\\nTrain labels count:\", len(train_df))\nprint(\"Validation labels count:\", len(val_df))\nprint(\"Test labels count:\", len(test_df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:39.828428Z","iopub.execute_input":"2025-04-21T15:46:39.828858Z","iopub.status.idle":"2025-04-21T15:46:39.931458Z","shell.execute_reply.started":"2025-04-21T15:46:39.828824Z","shell.execute_reply":"2025-04-21T15:46:39.929719Z"}},"outputs":[{"name":"stdout","text":"Train features shape: (9989, 1422)\nValidation features shape: (1109, 1422)\nTest features shape: (2610, 1422)\n\nTrain labels count: 9989\nValidation labels count: 1109\nTest labels count: 2610\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Load Labels\ny_train = train_df[\"Sentiment\"].values\ny_val = val_df[\"Sentiment\"].values\ny_test = test_df[\"Sentiment\"].values\n\n# Encode labels\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_val_encoded = label_encoder.transform(y_val)\ny_test_encoded = label_encoder.transform(y_test)\n\n# One-hot encode for model compatibility (if needed)\n#from tensorflow.keras.utils import to_categorical\n#y_train_cat = to_categorical(y_train_encoded)\n#y_val_cat = to_categorical(y_val_encoded)\n#y_test_cat = to_categorical(y_test_encoded)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:39.932938Z","iopub.execute_input":"2025-04-21T15:46:39.933337Z","iopub.status.idle":"2025-04-21T15:46:39.942814Z","shell.execute_reply.started":"2025-04-21T15:46:39.933305Z","shell.execute_reply":"2025-04-21T15:46:39.941660Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from keras.models import load_model\nfrom keras.layers import GRU, LSTM, Dense, Dropout, Bidirectional, Input\nfrom keras import Sequential\nimport tensorflow as tf\n\ntf.config.run_functions_eagerly(True)\n\n# Include all possible layer types used in the model\ncustom_objects = {\n    'GRU': GRU,\n    'LSTM': LSTM,\n    'Dense': Dense,\n    'Dropout': Dropout,\n    'Bidirectional': Bidirectional,\n    'Sequential': Sequential,\n    'Input': Input\n}\n\n# Load the model\nsentiment_model = load_model(\n    '/kaggle/input/meld-dataset/MELD-Features-Models/MELD.Features.Models/models/audio_weights_sentiment.hdf5',\n    custom_objects=custom_objects, compile=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:39.943886Z","iopub.execute_input":"2025-04-21T15:46:39.944255Z","iopub.status.idle":"2025-04-21T15:46:40.478272Z","shell.execute_reply.started":"2025-04-21T15:46:39.944223Z","shell.execute_reply":"2025-04-21T15:46:40.477201Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Trim to make it divisible by 33\ntrim_size = X2_val_aligned.shape[0] - (X2_val_aligned.shape[0] % 33)\nX2_val_trimmed = X2_val_aligned[:trim_size]\n\n# Reshape to (num_sequences, 33, 1611)\nX2_val_reshaped = X2_val_trimmed.reshape(-1, 33, 1422)\n\n# Test set\ntrim_size_test = X2_test_aligned.shape[0] - (X2_test_aligned.shape[0] % 33)\nX2_test_trimmed = X2_test_aligned[:trim_size_test]\nX2_test_reshaped = X2_test_trimmed.reshape(-1, 33, 1422)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:40.479626Z","iopub.execute_input":"2025-04-21T15:46:40.480053Z","iopub.status.idle":"2025-04-21T15:46:40.487042Z","shell.execute_reply.started":"2025-04-21T15:46:40.480007Z","shell.execute_reply":"2025-04-21T15:46:40.485445Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Validation\n# Trim features\ntrim_size_val = X2_val_aligned.shape[0] - (X2_val_aligned.shape[0] % 33)\nX2_val_trimmed = X2_val_aligned[:trim_size_val]\nX2_val_reshaped = X2_val_trimmed.reshape(-1, 33, 1422)\n\n# Trim labels accordingly\ny_val_trimmed = y_val_encoded[:trim_size_val]\n\n# Predict\nval_preds = sentiment_model.predict(X2_val_reshaped)\nprint(\"val_preds.shape:\", val_preds.shape)\n\n# Reshape model predictions to (1089, 7)\nval_preds_flat = val_preds.reshape(-1, val_preds.shape[-1])  # (1089, 7)\nval_preds_labels = np.argmax(val_preds_flat, axis=1)\n\ny_val_trimmed = y_val_encoded[:len(val_preds_labels)]\n\nprint(\"Validation Accuracy:\", accuracy_score(y_val_trimmed, val_preds_labels))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:40.489046Z","iopub.execute_input":"2025-04-21T15:46:40.489439Z","iopub.status.idle":"2025-04-21T15:46:42.691085Z","shell.execute_reply.started":"2025-04-21T15:46:40.489408Z","shell.execute_reply":"2025-04-21T15:46:42.689969Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 827ms/step\nval_preds.shape: (33, 33, 3)\nValidation Accuracy: 0.26538108356290174\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Testing\n# Trim features\ntrim_size_test = X2_test_aligned.shape[0] - (X2_test_aligned.shape[0] % 33)\nX2_test_trimmed = X2_test_aligned[:trim_size_test]\nX2_test_reshaped = X2_test_trimmed.reshape(-1, 33, 1422)\n\n# Trim labels accordingly\ny_test_trimmed = y_test_encoded[:trim_size_test]\n\n# Predict\ntest_preds = sentiment_model.predict(X2_test_reshaped)\nprint(\"test_preds.shape:\", test_preds.shape)\n\n# Reshape model predictions to (1089, 7)\ntest_preds_flat = test_preds.reshape(-1, test_preds.shape[-1])  # (1089, 7)\ntest_preds_labels = np.argmax(test_preds_flat, axis=1)\n\ny_test_trimmed = y_test_encoded[:len(test_preds_labels)]\n\n# Now it's safe\nprint(\"Test Accuracy:\", accuracy_score(y_test_trimmed, test_preds_labels))\nprint(\"\\nTest Classification Report:\")\nprint(classification_report(y_test_trimmed, test_preds_labels, target_names=label_encoder.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:46:42.691939Z","iopub.execute_input":"2025-04-21T15:46:42.692252Z","iopub.status.idle":"2025-04-21T15:46:45.848632Z","shell.execute_reply.started":"2025-04-21T15:46:42.692215Z","shell.execute_reply":"2025-04-21T15:46:45.847166Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 987ms/step\ntest_preds.shape: (79, 33, 3)\nTest Accuracy: 0.25009589566551593\n\nTest Classification Report:\n              precision    recall  f1-score   support\n\n    negative       0.26      0.52      0.35       833\n     neutral       0.20      0.01      0.01      1253\n    positive       0.23      0.41      0.29       521\n\n    accuracy                           0.25      2607\n   macro avg       0.23      0.31      0.22      2607\nweighted avg       0.22      0.25      0.18      2607\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}